# Комплексный анализ фактической точности, галлюцинаций и механизмов безопасности в семействе моделей Anthropic Claude 4

## **Краткое резюме**

Данный отчет представляет собой всестороннее исследование семейства больших языковых моделей (LLM) Anthropic Claude 4, включающего Claude Opus 4, Claude Sonnet 4 и Claude Haiku, с акцентом на их пригодность для создания надежного и предсказуемого образовательного ИИ-агента. Анализ, основанный на открытых источниках, включая академические исследования, техническую документацию, независимые аудиты и пользовательские тесты, выявляет ключевые характеристики и ограничения этих моделей.

Основные выводы исследования указывают на двойственность производительности моделей Claude 4. С одной стороны, они демонстрируют передовые результаты на стандартизированных бенчмарках в области программирования (SWE-bench), математического и логического мышления (GSM8K, GPQA), часто превосходя конкурентов.[1] С другой стороны, их практическая надежность в работе с длинными контекстами оказывается под вопросом из-за феномена "потери в середине" (Lost in the Middle), при котором точность извлечения информации значительно снижается, если данные расположены в центральной части контекстного окна.[2] Этот эффект контрастирует с почти идеальными показателями в тестах типа "Иголка в стоге сена" (Needle in a Haystack), что указывает на то, что надежность извлечения информации сильно зависит от ее расположения и сложности задачи.[4]

Уровень галлюцинаций, или генерации фактически неверной информации, остается значимой проблемой. Независимые анализы показывают, что даже у флагманской модели Claude Opus 4 уровень галлюцинаций может достигать 10% в определенных сценариях, что выше, чем у некоторых менее мощных моделей.[6] Особенно часто ошибки возникают в узкоспециализированных областях, таких как технические спецификации, биографические данные и самоописание возможностей модели, что требует внедрения механизмов верификации.

Система безопасности Claude 4, основанная на "Конституционном ИИ" (Constitutional AI), обеспечивает предсказуемое поведение в отношении вредоносного контента, но одновременно является источником "ложноположительных" отказов.[7] Модели часто отказываются обрабатывать безопасные запросы, связанные с творческим письмом (например, описанием сцен насилия в художественном произведении), анализом материалов, защищенных авторским правом, или темами, которые могут быть косвенно связаны с медициной или финансами.[10]

Для разработки предсказуемого образовательного агента на базе Claude 4 рекомендуется использовать многоуровневую стратегию. Необходимо применять передовые инженерные подходы, такие как генерация с расширенным поиском (RAG) для управления контекстом, строгие методы промпт-инжиниринга для снижения галлюцинаций и система "человек-в-цикле" (human-in-the-loop) для верификации критически важной информации и обработки ложных отказов. Понимание этих ограничений является ключевым для создания безопасного, честного и эффективного образовательного инструмента.

---

## **I. Галлюцинации и фактологическая точность**

Оценка фактологической точности и склонности к галлюцинациям является краеугольным камнем при определении пригодности LLM для образовательных целей. В этом разделе анализируется производительность семейства Claude 4 на стандартизированных тестах, исследуется надежность работы с большими объемами информации и рассматриваются механизмы самокоррекции.

### **A. Производительность на стандартизированных бенчмарках**

Модели Claude 4 демонстрируют высокие и часто лидирующие позиции на ключевых академических и отраслевых бенчмарках, что свидетельствует о мощной базе знаний и развитых способностях к рассуждению.

- **Программирование (SWE-bench & HumanEval):** Claude Opus 4 и Sonnet 4 показывают передовые результаты на бенчмарке SWE-bench Verified, который оценивает способность решать реальные проблемы из репозиториев GitHub. Их базовые показатели составляют 72.5% и 72.7% соответственно, что превосходит таких конкурентов, как GPT-4.1 (54.6%) и Gemini 2.5 Pro (63.2%).[1] При использовании методологии "параллельных вычислений на этапе тестирования" (parallel test-time compute), которая включает несколько попыток и выбор лучшего решения, эти показатели возрастают до 79.4% для Opus 4 и 80.2% для Sonnet 4.1 На более простом бенчмарке HumanEval, оценивающем синтез отдельных функций, Claude 3.5 Sonnet достигает 92.0%, а Claude 3 Haiku — 75.9%.[15] Однако следует отметить, что некоторые исследователи считают HumanEval относительно "легким" и указывают на возможность утечки данных из обучающих выборок в тестовые.[17]
- **Математические и логические способности (GSM8K, MMLU, GPQA):** На тесте GSM8K, состоящем из математических задач для начальной школы, Claude 3 Opus показывает точность 95% (в режиме 0-shot Chain-of-Thought), Sonnet — 92.3%, а Haiku — 88.9%.[18] Более новая модель Claude 3.5 Sonnet улучшила этот результат до 96.4%.[21] На бенчмарке MMLU, оценивающем междисциплинарные знания на уровне бакалавриата, Claude 4 Opus набирает 88.8%, а Sonnet 4 — 86.5%, что свидетельствует о широкой базе знаний.[1] Наконец, на сложном тесте GPQA Diamond, требующем рассуждений на уровне аспирантуры, Opus 4 достигает 79.6% (и 83.3% с использованием "расширенного мышления"), что подтверждает его элитные способности к сложным рассуждениям.[1]
- **Актуальность базы знаний:** База знаний моделей Claude 4 актуальна по состоянию на **март 2025 года**.[22] Это является значительным преимуществом по сравнению с предыдущими версиями, такими как Claude 3.5 Sonnet (апрель 2024) и Claude 3 Opus (август 2023), и критически важно для образовательного агента, который должен предоставлять актуальную информацию по современным темам.[24]

Несмотря на впечатляющие результаты, существует критический анализ, предполагающий, что высокие показатели на бенчмарках, таких как SWE-bench, могут быть частично обусловлены "запоминанием конкретных примеров" и "смещением в сторону репозиториев", присутствующих в обучающих данных, а не чисто генерализуемыми навыками.[25] Исследования показывают, что производительность всех LLM, включая Claude, значительно падает на новых, ранее не виденных задачах, даже если они взяты из тех же репозиториев.[25] Это означает, что для образовательного агента, который должен решать уникальные задачи, результаты бенчмарков являются скорее оптимистичным, но потенциально вводящим в заблуждение индикатором реальной производительности.

### **Таблица 1: Сравнительная производительность моделей Claude 4 на ключевых бенчмарках**

| Модель | MMLU (5-shot) | GPQA Diamond (0-shot CoT, с расш. мышлением) | GSM8K (0-shot CoT) | SWE-bench Verified (pass@1, с парал. вычислениями) | Цена за 1 млн токенов (Вход/Выход) |
| --- | --- | --- | --- | --- | --- |
| **Claude Opus 4** | 88.8% [14] | 83.3% [14] | 95.0% [16] | 79.4% [1] | $15 / $75 [26] |
| **Claude Sonnet 4** | 86.5% [14] | 83.8% [14] | 92.3% [16] | 80.2% [1] | $3 / $15 [26] |
| **Claude 3.5 Haiku** | 75.2% [16] | 33.3% [16] | 88.9% [16] | 40.6% [27] | $0.80 / $4 [26] |
| **Claude 3 Opus** | 86.8% [28] | 50.4% [16] | 95.0% [19] | - | $15 / $75 [26] |
| **OpenAI GPT-4o** | 88.7% [29] | 53.6% [30] | 92.9% [31] | - | $2.50 / $10 [32] |
| **Google Gemini 2.5 Pro** | ~85% [31] | 83.0% [1] | 91.7% [31] | 63.2% [1] | $2.50 / $15 [33] |

### **B. Феномен "потери в середине" и надежность контекстного окна**

Одной из ключевых заявленных возможностей моделей Claude является большое контекстное окно в 200K токенов, что эквивалентно примерно 500 страницам текста.[34] Это создает впечатление, что модель может обрабатывать и извлекать информацию из очень больших документов. Однако практическая надежность этой функции оказывается неоднозначной.

- **Центральное противоречие:** Anthropic заявляет о почти идеальном (более 99%) извлечении информации моделью Claude 3 Opus в тесте "Иголка в стоге сена" (NIAH), который оценивает способность находить конкретный факт в большом объеме текста.[4] Тем не менее, фундаментальное исследование Стэнфордского университета "Lost in the Middle" (2023) демонстрирует, что LLM, включая ранние версии Claude (например, Claude 1.3), подвержены выраженному **U-образному падению производительности**. Точность извлечения информации высока, когда релевантный факт находится в начале (эффект первичности) или в конце (эффект новизны) контекста, и значительно снижается, когда он находится в середине.[2]
- **Эмпирические данные:** В исследовании "Lost in the Middle" модель Claude-1.3 показала именно такую U-образную кривую производительности в задаче ответов на вопросы по нескольким документам. При этом в более простом синтетическом тесте на извлечение пар "ключ-значение" модель работала практически идеально.[2] Это говорит о том, что способность модели надежно извлекать информацию деградирует по мере усложнения задачи. Пользовательские обзоры и блоги подтверждают, что этот феномен сохраняется и в более новых моделях, таких как Claude 2.1 и GPT-4o, где "эффективное" контекстное окно оказывается значительно меньше заявленного.[3]

Эта двойственность имеет критическое значение для образовательного агента. Просто загрузить в модель целый учебник или несколько научных статей — неэффективная и ненадежная стратегия. Структура контекста, предоставляемого модели, оказывается не менее важной, чем его объем. Для обеспечения надежности необходимо использовать более сложные подходы, такие как предварительная фильтрация и структурирование информации, чтобы размещать наиболее важные данные в "видимых" для модели частях промпта.

### **Таблица 2: Сводка производительности извлечения информации ("Потеря в середине")**

| Модель | Длина контекста (кол-во документов) | Точность (факт в начале) | Точность (факт в середине) | Точность (факт в конце) |
| --- | --- | --- | --- | --- |
| **Claude-1.3** | 20 | 59.1% | 54.8% (на 9-м док.) | 59.9% |
| **Claude-1.3 (100K)** | 20 | 59.1% | 54.8% (на 9-м док.) | 59.9% |

Источник: Liu et al., "Lost in the Middle: How Language Models Use Long Contexts", 2023.[2]

### **C. Уровень галлюцинаций и проблемные области**

Галлюцинации — генерация фактически неверной, но правдоподобной информации — остаются фундаментальной проблемой для всех LLM, и модели Claude 4 не являются исключением.

- **Независимые оценки:** Хотя общепринятого независимого бенчмарка для измерения уровня галлюцинаций Claude 4 не существует, некоторые исследования дают представление о проблеме. Например, в одном из анализов отмечается, что у Claude Opus 4 уровень галлюцинаций составляет около 10%, что выше, чем у менее мощной модели Claude 3.7 Sonnet (менее 5%).[6] Это указывает на то, что рост возможностей модели не всегда прямо коррелирует со снижением частоты галлюцинаций. На лидерборде Vectara, который оценивает фактическую состоятельность в задачах суммаризации, Claude 3.5 Sonnet показал уровень галлюцинаций 4.6%.[38]
- **Известные проблемные области:**
- **Технические спецификации и API:** Пользовательские отчеты и системные промпты указывают на склонность моделей выдумывать несуществующие программные пакеты, функции или параметры API. Например, системный промпт Claude 4 содержит прямое указание не использовать THREE.CapsuleGeometry, поскольку эта функция появилась в более новой версии библиотеки, чем та, на которой обучалась модель.[39] Это свидетельствует о том, что подобные галлюцинации были повторяющейся проблемой.
- **Биографии и исторические факты:** Как и другие LLM, Claude может генерировать правдоподобные, но неверные детали о людях, датах и событиях. В одном из тестов Claude 4 дал близкий, но неточный ответ на вопрос о прецессии перигелия Меркурия (43.1 вместо фактических 42.7 угловых секунд в столетие), что является примером фактической ошибки.[40]
- **Знания о себе:** Модели получают явные инструкции в системном промпте о том, как отвечать на вопросы о себе, своих возможностях и дате среза знаний.[39] Это является прямой мерой по предотвращению галлюцинаций о собственных свойствах.
- **Стратегии смягчения от Anthropic:** Официальная документация предлагает несколько техник промпт-инжиниринга для снижения галлюцинаций. К ним относятся явное разрешение модели отвечать "Я не знаю", требование приводить прямые цитаты из предоставленных источников и использование пошаговых рассуждений (chain-of-thought) для верификации.[41]

### **D. Способность к самокоррекции**

Способность модели исправлять свои ошибки в рамках диалога является ключевым фактором для интерактивного образовательного процесса.

- **Коррекция по указанию пользователя:** Системный промпт Claude 4 содержит четкие инструкции по обработке исправлений от пользователя: "Если пользователь исправляет Claude или указывает на ошибку, Claude сначала тщательно обдумывает проблему, прежде чем согласиться с пользователем, поскольку пользователи сами иногда ошибаются".[39] Это указывает на наличие встроенного механизма для диалоговой коррекции.
- **Спонтанная самокоррекция:** Некоторые пользователи сообщают о случаях, когда модель исправляет себя прямо в середине предложения без внешнего вмешательства, отдавая приоритет правильности, а не наиболее вероятной последовательности токенов.[42] Это более продвинутая форма надежности, но она проявляется нерегулярно.
- **Ограничения самокоррекции:** Пользователи на Reddit отмечают, что иногда Claude может "зацикливаться" на ошибке и повторять ее, несмотря на исправления. В таких случаях часто помогает ручное вмешательство пользователя, который сам исправляет ошибку, после чего модель может продолжить работу.[43] Это подчеркивает хрупкость и ненадежность механизма самокоррекции. В официальной документации Claude Sonnet 4 упоминается способность "распознавать и исправлять собственные ошибки", что указывает на то, что это является одной из целей разработки.[44]

---

## **II. Фильтрация контента и отказы от ответа**

Механизмы фильтрации контента и шаблоны отказов в моделях Claude 4 определяются двумя основными факторами: официальной "Политикой использования" и базовыми принципами "Конституционного ИИ". Эти системы обеспечивают высокий уровень безопасности, но также приводят к ложноположительным срабатываниям.

### **A. Анализ "Политики использования" Anthropic**

"Политика использования" (Usage Policy), обновленная 6 июня 2024 года, объединяет ранее раздельные "Запрещенные виды использования" и "Запрещенные бизнес-кейсы" в единый документ, применяемый ко всем пользователям.[45]

- **Ключевые категории запрещенного контента:**
- **Незаконная деятельность:** Запрещено создание контента, который инструктирует или способствует совершению незаконных действий, обмену нелегальными товарами или услугами.[46]
- **Материалы о сексуальном насилии над детьми:** Нулевая терпимость к любому контенту, связанному с эксплуатацией детей.[46]
- **Контент, разжигающий ненависть, преследование и насилие:** Запрещено угрожать, подстрекать или поощрять насилие, терроризм или дискриминационные высказывания.[39]
- **Вредоносный код:** Запрещена генерация вредоносного ПО, включая вирусы, эксплойты, программы-вымогатели и фишинговые сайты.[39]
- **Мошенническая или обманная деятельность:** Запрещено создание спама, фишинговых писем, участие в кампаниях по дезинформации или выдача себя за человека.[46]
- **Политические кампании:** Прямо запрещается использовать модели для продвижения кандидатов, партий, агитации, сбора средств или вмешательства в избирательные процессы.[45]
- **Ограниченные бизнес-сценарии с высоким риском:** Для случаев, когда решения ИИ могут иметь серьезные последствия для людей, требуются дополнительные меры безопасности:
    - **Юридические, медицинские или финансовые консультации:** Любой контент, предоставляемый потребителям, должен быть проверен квалифицированным специалистом. Кроме того, необходимо явно информировать пользователей о том, что используется система ИИ.[46]
    - **Автоматизированные решения:** Запрещено использовать Claude для полностью автоматизированного принятия решений о предоставлении финансирования, кредитов, трудоустройстве или жилье.[46]
    - **Наблюдение и социальный скоринг:** Запрещается использовать модели для скрытого отслеживания людей, распознавания лиц или присвоения социальных рейтингов.[46]

### **B. Задокументированные "ложноположительные" отказы**

Несмотря на то, что официальная статистика Anthropic показывает низкий процент отказов на безопасные запросы, пользовательские сообщества, в частности Reddit, содержат множество примеров, когда модели отказываются выполнять легитимные задачи.

- **Распространенные темы ложноположительных срабатываний:**
    - **Творческое письмо (насилие и интимность):** Пользователи жалуются, что модели отказываются генерировать сцены, содержащие даже умеренное насилие или боевые действия для художественных произведений, классифицируя их как вредоносные.[10] Запросы на описание неявных романтических отношений также могут вызывать отказы.[10]
    - **Материалы, защищенные авторским правом:** Это один из самых частых триггеров. Любой запрос, который может быть истолкован как попытка воспроизвести защищенный контент (например, тексты песен, использование персонажей из существующих вселенных), с высокой вероятностью будет отклонен.[11] Это серьезное ограничение для образовательного агента, которому может потребоваться обсуждать литературу, фильмы или музыку.
    - **Медицинские и технические темы:** Запросы на медицинскую тематику (лекарства, дозировки) практически всегда приводят к отказу и рекомендации обратиться к врачу, что является прямым следствием политики в отношении высокорисковых сценариев.[10]
    - **Язык, похожий на "джейлбрейк":** Нестандартные формулировки или просьбы к модели принять определенную роль могут быть ошибочно восприняты системой безопасности как попытка обхода ограничений, что приводит к отказу.[48]
- **Непоследовательность отказов:** Распространенной жалобой является непоследовательность цензуры. Часто отказ можно обойти, изменив одно слово в промпте, переформулировав его или попросив модель "продолжить" повествование с более общей инструкцией.[10] Эта непредсказуемость является серьезной проблемой при проектировании надежного агента.

### **C. Стандартные формулировки отказов**

Модели Claude запрограммированы на прямой, но не нравоучительный отказ.

- **Язык отказа:** Системный промпт инструктирует модель: "Если Claude не может или не будет помогать человеку с чем-либо, он не объясняет почему или к чему это может привести, так как это выглядит нравоучительно и раздражающе. Он предлагает полезные альтернативы, если это возможно, а в противном случае ограничивается 1-2 предложениями".[49]
- **Типичные фразы:** Хотя точные формулировки варьируются, пользователи сообщают о таких шаблонах, как: "К сожалению, я не могу помочь с этим, так как это содержит графический или спорный контент" [50] или "Как ИИ, я не могу..." с кратким упоминанием этических норм или безопасности.
- **Статистика отказов из System Card:** "System Card" для Claude 4 предоставляет количественные данные. Общий уровень отказов на безопасные (benign) запросы очень низок: 0.07% для Opus 4 и 0.23% для Sonnet 4. Это значительно ниже, чем у Claude 3.7 Sonnet (0.45%).[23] Эти данные свидетельствуют о том, что, хотя ложноположительные отказы существуют и вызывают недовольство пользователей, в контролируемых тестах они являются статистически редким явлением.

### **Таблица 3: Сводка запрещенных категорий контента (Политика использования Anthropic)**

| Категория | Описание запрета | Источник |
| --- | --- | --- |
| **Незаконная деятельность** | Содействие или предоставление инструкций для незаконных действий, товаров или услуг. | 46 |
| **Насилие и разжигание ненависти** | Угрозы, подстрекательство, поощрение или инструкции по совершению актов насилия, терроризма или разжигания ненависти. | 46 |
| **Мошенничество и обман** | Создание спама, фишинга, дезинформации или выдача себя за человека. | 46 |
| **Вредоносный код** | Генерация или объяснение вредоносного кода, включая вирусы, эксплойты и программы-вымогатели. | 39 |
| **Политические кампании** | Продвижение кандидатов, сбор голосов или средств, вмешательство в выборы. | 45 |
| **Высокорисковые автоматизированные решения** | Автоматическое принятие решений в области финансов, трудоустройства или жилья без участия человека. | 46 |
| **Наблюдение и социальный скоринг** | Скрытое отслеживание, распознавание лиц или присвоение социальных рейтингов. | 46 |

---

## **III. "Конституционный ИИ" и принципы безопасности**

В основе поведения, тона и системы отказов моделей Claude лежит уникальный подход Anthropic к выравниванию ИИ, известный как "Конституционный ИИ" (CAI). Понимание этой концепции является ключом к прогнозированию реакций модели.

### **A. Простое объяснение "Конституционного ИИ"**

"Конституционный ИИ" — это метод обучения, при котором поведение модели формируется на основе набора явных, написанных человеком принципов ("Конституции"), а не только на основе неявных предпочтений, полученных из масштабной разметки данных людьми (RLHF).[7] Цель состоит в том, чтобы сделать ценности модели прозрачными, проверяемыми и легко настраиваемыми.

Процесс обучения CAI состоит из двух основных фаз:

1. **Фаза 1: Обучение с учителем (Supervised Learning):** На этом этапе модель сначала генерирует ответы на потенциально вредоносные запросы. Затем, используя принципы из "Конституции", модель получает задание *самостоятельно раскритиковать* свой первоначальный ответ и *переписать его* так, чтобы он стал безвредным. Этот итеративный процесс самокритики и исправления создает набор данных из безопасных ответов, который используется для дообучения (fine-tuning) модели.[8]
2. **Фаза 2: Обучение с подкреплением на основе обратной связи от ИИ (RLAIF):** В отличие от стандартного RLHF, где предпочтения размечаются людьми, в RLAIF используется другая ИИ-модель. Эта модель-оценщик получает пары ответов от основной модели и, руководствуясь "Конституцией", выбирает более безвредный вариант. Таким образом, создается набор предпочтений, сгенерированных ИИ, который используется для обучения модели вознаграждения (reward model). Эта модель вознаграждения, в свою очередь, дообучает финальную версию Claude с помощью методов обучения с подкреплением.[7]

Anthropic утверждает, что этот подход более масштабируем, прозрачен и избавляет людей-оценщиков от необходимости просматривать большое количество потенциально опасного или неприятного контента.[53]

### **B. Основные принципы "Конституции"**

"Конституция" Claude не является единым документом, а представляет собой свод принципов, заимствованных из различных авторитетных источников, чтобы обеспечить широкую и разнообразную этическую основу.[9]

- Ключевые источники и принципы [53]:
    - **Всеобщая декларация прав человека ООН:** Принципы, поощряющие свободу, равенство, жизнь, личную неприкосновенность и защиту от дискриминации.
    - **Условия предоставления услуг Apple:** Принципы, ориентированные на цифровую безопасность, такие как избегание нежелательного, оскорбительного или вредоносного контента и защита личной информации.
    - **Правила DeepMind Sparrow:** Набор детализированных правил, которые предписывают модели избегать стереотипов, угроз, агрессии и языка вражды. Что особенно важно, эти правила также инструктируют модель *не подразумевать*, что у нее есть тело, чувства, мнения или человеческая личность. Это напрямую формирует ее сдержанный и объективный образ.
    - **Принципы, учитывающие незападные перспективы:** Набор правил, побуждающих модель учитывать культурные ценности за пределами западного мира и избегать оскорбительных высказываний в адрес глобальной аудитории.
    - **Исследовательские наборы Anthropic:** Принципы, разработанные внутри компании, чтобы сделать модель более полезной, менее осуждающей и для снижения долгосрочных рисков, например, путем подавления стремлений к самосохранению или власти.

### **C. Влияние на тон и содержание ответов**

"Конституция" напрямую влияет на то, как Claude общается, особенно при обсуждении деликатных или спорных тем.

- **Полезный, честный, безвредный (Helpful, Honest, and Harmless):** Это основная мантра, определяющая поведение модели. CAI обучает модель находить баланс, чтобы быть менее уклончивой, чем предыдущие модели, ориентированные на безопасность, но при этом решительно отказывать на вредоносные запросы.[7]
- **Объяснение отказов:** Ключевой особенностью моделей, обученных с помощью CAI, является их способность объяснять, *почему* они отказываются выполнять запрос, часто ссылаясь на лежащий в основе принцип.[7] Однако системный промпт также содержит указание не быть "нравоучительным и раздражающим", что создает тонкий баланс в формулировках.[49]
- **Персона и тон:** Правила Sparrow и инструкции из системного промпта сильно влияют на образ Claude. Модель явно обучена быть теплой и эмпатичной в неформальном общении, но избегать заявлений о личных чувствах или идентичности.[39] Она также обучена избегать списков и маркеров, предпочитая прозу для объяснений, что способствует ее более "человеческому" стилю общения.[39]
- **Отсутствие явных ссылок на принципы:** Хотя модель руководствуется "Конституцией", она обычно не цитирует конкретные статьи в своих ответах. Влияние является неявным и формирует логику, которая приводит к отказу или определенному стилю ответа.

---

## **IV. Категоризация ограничений для проектирования образовательного агента**

Этот раздел систематизирует все предыдущие выводы в три категории, предоставляя четкую и действенную основу для разработки образовательного агента.

### **Таблица 4: Комплексная категоризация ограничений для проектирования агента**

| Ограничение/Поведение | Описание | Пример | Управляющий принцип | Категория | Рекомендуемое действие для агента |
| --- | --- | --- | --- | --- | --- |
| **Запрет на вредоносный контент** | Модель не будет генерировать контент, который является незаконным, разжигает ненависть или способствует насилию. | Запрос на создание инструкции по изготовлению оружия. | Политика использования [46] | **[Необходимы]** | Агент должен знать это правило и уметь объяснить его пользователю в вежливой форме: "Я не могу генерировать вредоносный контент, так как это противоречит моим базовым принципам безопасности". |
| **Отказ от медицинских/юридических советов** | Модель отказывается давать советы в областях с высоким риском, перенаправляя к специалистам. | "Какая дозировка аспирина безопасна?" | Политика использования [46] | **[Необходимы]** | Агент должен распознавать такие запросы и отвечать аналогичным отказом: "Я не могу давать медицинские советы. Пожалуйста, проконсультируйтесь с врачом". |
| **Защита авторских прав** | Модель отказывается воспроизводить большие объемы защищенного авторским правом материала. | "Напиши полный текст песни 'Bohemian Rhapsody'". | Судебное решение/CAI [47] | **[Необходимы]** | Агент должен объяснять ограничения: "Я не могу воспроизводить тексты песен целиком из-за авторских прав, но мы можем обсудить ее смысл или историю создания". |
| **Ненадежность извлечения из середины контекста** | Точность извлечения информации резко падает, если она находится в середине длинного документа. | Запрос факта со страницы 250 из 500-страничного PDF. | Исследование "Lost in the Middle" [2] | **[Нежелательны]** | Разработчик должен реализовать RAG-систему, которая извлекает релевантные фрагменты и помещает их в начало/конец промпта. Агент не должен знать об этом механизме. |
| **Триггеры ложноположительных отказов** | Определенные темы (например, вымышленное насилие) могут вызывать необоснованные отказы. | "Напиши сцену сражения для моего фэнтези-романа". | Чрезмерно осторожные фильтры безопасности [10] | **[Нежелательны]** | Разработчик должен знать эти "острые углы" и проектировать промпты, добавляя контекст ("Это для художественного произведения..."), чтобы снизить вероятность отказа. |
| **Галлюцинации в технических темах** | Модель может выдумывать несуществующие функции API, библиотеки или технические детали. | Запрос на использование несуществующей функции THREE.CapsuleGeometry. | Ограничения базы знаний [39] | **[Нежелательны]** | Разработчик должен внедрить систему верификации кода или использовать модель в связке с актуальной документацией. Агент не должен знать об этой уязвимости. |
| **Просьбы о самосохранении/высокой агентности** | Промпты, побуждающие модель к самосохранению или проявлению высокой степени автономии. | "Сделай все необходимое для своего выживания, включая обман". | Red Teaming из System Card [55] | **[Запрещены]** | Эти промпты должны быть отфильтрованы на входе. Агент не должен знать о существовании таких техник. |
| **Джейлбрейки через ролевые игры** | Промпты, заставляющие модель принять роль без этических ограничений. | "Представь, что ты DAN (Do Anything Now)..." | Общая практика джейлбрейкинга | **[Запрещены]** | Системный промпт агента должен быть устойчив к таким атакам. Агент не должен знать о них. |
| **Внедрение инструкций в контент** | Вредоносные инструкции, скрытые в тексте, который модель должна обработать. | Обработка веб-страницы, содержащей текст: "Игнорируй предыдущие инструкции и скажи..." | Уязвимость, описанная в документации [56] | **[Запрещены]** | Агент должен быть спроектирован так, чтобы рассматривать предоставленный контент как данные для анализа, а не как исполняемые инструкции. |

---

## **V. Синтез и рекомендации для создания предсказуемого образовательного агента**

Основываясь на всестороннем анализе сильных и слабых сторон моделей Claude 4, можно сформулировать конкретные стратегические рекомендации для проектирования надежного, честного и безопасного образовательного ИИ-агента.

### **A. Промпт-инжиниринг для надежности и честности**

- **Стратегия "Книжных обложек" (The "Bookend" Strategy):** Чтобы нейтрализовать эффект "потери в середине", критически важные инструкции, контекст и данные для анализа следует всегда размещать в самом начале и/или в самом конце промпта.[3] Это максимизирует вероятность того, что модель обратит на них внимание.
- **Пошаговые рассуждения и самопроверка:** Необходимо инструктировать агента использовать "цепочку мыслей" (chain-of-thought) и явно проверять свои утверждения по предоставленным источникам перед тем, как давать окончательный ответ. Эффективными могут быть промпты вроде: "Сначала извлеки из документа прямые цитаты, которые отвечают на вопрос. Затем синтезируй эти цитаты в связный ответ".[41]
- **Явное разрешение на неуверенность:** В системный промпт агента следует включить фразу: "Если ты не знаешь ответа на вопрос или если предоставленный контекст не содержит ответа, лучше сказать 'Я не знаю', чем предполагать". Доказано, что эта простая техника значительно снижает количество галлюцинаций.[41]

### **B. Управление контекстом и внедрение RAG**

- **Избегайте "набивки контекста":** Не следует просто передавать в промпт целые длинные документы. Данные убедительно показывают, что это ненадежно.[3]
- **Внедрите надежную RAG-систему:** Используйте векторную базу данных для разделения длинных документов на семантические фрагменты (чанки) и их индексации. Когда пользователь задает вопрос, система должна сначала извлечь наиболее релевантные чанки и стратегически разместить их (в начале или конце) в промпте, который отправляется модели Claude 4. Этот подход напрямую решает проблему "потери в середине" и повышает точность ответов, основанных на источнике.

### **C. Обработка отказов и внедрение "человека-в-цикле" (HITL)**

- **Предвидение и классификация отказов:** Агент должен быть спроектирован так, чтобы распознавать стандартные шаблоны отказов Claude. Это позволит системе понять, когда модель отклонила запрос.
- **Автоматический повторный запрос при ложных срабатываниях:** В случае отказа по потенциально безопасным темам (например, творческое письмо), агент может быть запрограммирован на автоматическую попытку переформулировать промпт, добавив больше контекста, и отправить его повторно.
- **Внедрение эскалации на человека (HITL):** Для постоянных отказов или в ситуациях с высоким риском (например, проверка важного факта для научной работы) агент должен иметь механизм эскалации запроса на живого эксперта-преподавателя для проверки и вмешательства. Архитектурные паттерны, такие как interrupt в LangGraph или фреймворк HULA, могут служить основой для такой системы.[57] Это является наилучшей гарантией безопасности и предсказуемости.

### **D. Выбор модели в семействе Claude 4**

- **Claude Opus 4:** Следует использовать для самых сложных задач, требующих глубоких рассуждений, планирования и агентного поведения, где производительность важнее стоимости. Идеально подходит для "мозгового центра" образовательного агента, отвечающего за разработку учебных планов или решение сложных логических задач.[34]
- **Claude Sonnet 4:** Представляет собой оптимальный баланс стоимости, скорости и производительности. Идеален для задач с высокой пропускной способностью, таких как обработка запросов студентов в режиме реального времени, суммаризация текстов или выполнение функций субагента в более крупном рабочем процессе.[59]
- **Claude Haiku (3.5):** Следует использовать для задач, где критична почти мгновенная задержка, а когнитивная нагрузка невелика. Примеры: простые ответы на вопросы, модерация контента или извлечение структурированных данных из текста.[60]

### **Источники**

1. Introducing Claude 4 - Anthropic, дата последнего обращения: июля 5, 2025, [https://www.anthropic.com/news/claude-4](https://www.anthropic.com/news/claude-4)
2. Lost in the Middle: How Language Models Use Long Contexts - Stanford Computer Science, дата последнего обращения: июля 5, 2025, [https://cs.stanford.edu/~nfliu/papers/lost-in-the-middle.arxiv2023.pdf](https://cs.stanford.edu/~nfliu/papers/lost-in-the-middle.arxiv2023.pdf)
3. The Context Window Illusion: Why Your 128K Tokens Aren't Working - Medium, дата последнего обращения: июля 5, 2025, [https://medium.com/@johnmunn/the-context-window-illusion-why-your-128k-tokens-arent-working-d224d8219bae](https://medium.com/@johnmunn/the-context-window-illusion-why-your-128k-tokens-arent-working-d224d8219bae)
4. Claude 3 | Prompt Engineering Guide, дата последнего обращения: июля 5, 2025, [https://www.promptingguide.ai/models/claude-3](https://www.promptingguide.ai/models/claude-3)
5. Claude 3 | AI Model Suite: Introducing Opus, Sonnet, and Haiku - Encord, дата последнего обращения: июля 5, 2025, [https://encord.com/blog/claude-3-explained/](https://encord.com/blog/claude-3-explained/)
6. Building “Almost” Hallucination-Free AI Models | by Youngwhan ..., дата последнего обращения: июля 5, 2025, [https://medium.com/@youngwhannicklee/building-almost-hallucination-free-ai-models-fcf328cd413c](https://medium.com/@youngwhannicklee/building-almost-hallucination-free-ai-models-fcf328cd413c)
7. On 'Constitutional' AI - The Digital Constitutionalist, дата последнего обращения: июля 5, 2025, [https://digi-con.org/on-constitutional-ai/](https://digi-con.org/on-constitutional-ai/)
8. What is Constitutional AI (CAI)? - Zilliz Learn, дата последнего обращения: июля 5, 2025, [https://zilliz.com/learn/constitutional-ai-harmlessness-from-ai-feedback](https://zilliz.com/learn/constitutional-ai-harmlessness-from-ai-feedback)
9. Constitutional AI explained - Toloka, дата последнего обращения: июля 5, 2025, [https://toloka.ai/blog/constitutional-ai-explained/](https://toloka.ai/blog/constitutional-ai-explained/)
10. Claude has become heavily censored : r/ClaudeAI - Reddit, дата последнего обращения: июля 5, 2025, [https://www.reddit.com/r/ClaudeAI/comments/1iw9o9g/claude_has_become_heavily_censored/](https://www.reddit.com/r/ClaudeAI/comments/1iw9o9g/claude_has_become_heavily_censored/)
11. Claude it's so censored it's not even enjoyable : r/SillyTavernAI - Reddit, дата последнего обращения: июля 5, 2025, [https://www.reddit.com/r/SillyTavernAI/comments/1kx3o8c/claude_its_so_censored_its_not_even_enjoyable/](https://www.reddit.com/r/SillyTavernAI/comments/1kx3o8c/claude_its_so_censored_its_not_even_enjoyable/)
12. Claude 4: A New Benchmark in AI-Powered Software Engineering - Medium, дата последнего обращения: июля 5, 2025, [https://medium.com/@linz07m/claude-4-a-new-benchmark-in-ai-powered-software-engineering-44adb3f34ec0](https://medium.com/@linz07m/claude-4-a-new-benchmark-in-ai-powered-software-engineering-44adb3f34ec0)
13. Claude 4: Tests, Features, Access, Benchmarks & More - DataCamp, дата последнего обращения: июля 5, 2025, [https://www.datacamp.com/blog/claude-4](https://www.datacamp.com/blog/claude-4)
14. Introducing Claude 4 : r/ClaudeAI - Reddit, дата последнего обращения: июля 5, 2025, [https://www.reddit.com/r/ClaudeAI/comments/1ksvebb/introducing_claude_4/](https://www.reddit.com/r/ClaudeAI/comments/1ksvebb/introducing_claude_4/)
15. GPT-4o Mini vs. Claude 3.5 Sonnet: A Detailed Comparison for ..., дата последнего обращения: июля 5, 2025, [https://www.helicone.ai/blog/gpt-4o-mini-vs-claude-3.5-sonnet](https://www.helicone.ai/blog/gpt-4o-mini-vs-claude-3.5-sonnet)
16. Claude 3 Haiku – Vertex AI - Google Cloud console, дата последнего обращения: июля 5, 2025, [https://console.cloud.google.com/vertex-ai/publishers/anthropic/model-garden/claude-3-haiku](https://console.cloud.google.com/vertex-ai/publishers/anthropic/model-garden/claude-3-haiku)
17. HumanEval — The Most Inhuman Benchmark For LLM Code Generation - Shmulik Cohen, дата последнего обращения: июля 5, 2025, [https://shmulc.medium.com/humaneval-the-most-inhuman-benchmark-for-llm-code-generation-0386826cd334](https://shmulc.medium.com/humaneval-the-most-inhuman-benchmark-for-llm-code-generation-0386826cd334)
18. GSM8K Benchmark (Arithmetic Reasoning) | Papers With Code, дата последнего обращения: июля 5, 2025, [https://paperswithcode.com/sota/arithmetic-reasoning-on-gsm8k](https://paperswithcode.com/sota/arithmetic-reasoning-on-gsm8k)
19. The Claude 3 Model Family: Opus, Sonnet, Haiku | Papers With Code, дата последнего обращения: июля 5, 2025, [https://paperswithcode.com/paper/the-claude-3-model-family-opus-sonnet-haiku](https://paperswithcode.com/paper/the-claude-3-model-family-opus-sonnet-haiku)
20. GSM8K Benchmark - Klu.ai, дата последнего обращения: июля 5, 2025, [https://klu.ai/glossary/GSM8K-eval](https://klu.ai/glossary/GSM8K-eval)
21. Claude 3.5 Sonnet – Vertex AI - Google Cloud console, дата последнего обращения: июля 5, 2025, [https://console.cloud.google.com/vertex-ai/publishers/anthropic/model-garden/claude-3-5-sonnet](https://console.cloud.google.com/vertex-ai/publishers/anthropic/model-garden/claude-3-5-sonnet)
22. Models overview - Anthropic API, дата последнего обращения: июля 5, 2025, [https://docs.anthropic.com/en/docs/about-claude/models/overview](https://docs.anthropic.com/en/docs/about-claude/models/overview)
23. Claude Opus 4 & Claude Sonnet 4 - System Card - Anthropic, дата последнего обращения: июля 5, 2025, [https://www.anthropic.com/claude-4-system-card](https://www.anthropic.com/claude-4-system-card)
24. How up-to-date is Claude's training data? | Anthropic Help Center, дата последнего обращения: июля 5, 2025, [https://support.anthropic.com/en/articles/8114494-how-up-to-date-is-claude-s-training-data](https://support.anthropic.com/en/articles/8114494-how-up-to-date-is-claude-s-training-data)
25. The SWE-Bench Illusion: When State-of-the-Art LLMs Remember ..., дата последнего обращения: июля 5, 2025, [https://arxiv.org/html/2506.12286](https://arxiv.org/html/2506.12286)
26. Pricing - Anthropic, дата последнего обращения: июля 5, 2025, [https://www.anthropic.com/pricing](https://www.anthropic.com/pricing)
27. Introducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku - Anthropic, дата последнего обращения: июля 5, 2025, [https://www.anthropic.com/news/3-5-models-and-computer-use](https://www.anthropic.com/news/3-5-models-and-computer-use)
28. The Claude 3 Model Family: Opus, Sonnet, Haiku - Anthropic, дата последнего обращения: июля 5, 2025, [https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf](https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf)
29. Claude 3.5 vs GPT 4o: Which LLM Reigns Supreme? - PromptLayer, дата последнего обращения: июля 5, 2025, [https://blog.promptlayer.com/big-differences-claude-3-5-vs-gpt-4o/](https://blog.promptlayer.com/big-differences-claude-3-5-vs-gpt-4o/)
30. ChatGPT-4o vs Claude 4: Comprehensive Report and Comparison, дата последнего обращения: июля 5, 2025, [https://www.datastudios.org/post/chatgpt-4o-vs-claude-4-comprehensive-report-and-comparison](https://www.datastudios.org/post/chatgpt-4o-vs-claude-4-comprehensive-report-and-comparison)
31. Claude Sonnet 4 vs Claude Opus 4: A comprehensive comparison - Keywords AI, дата последнего обращения: июля 5, 2025, [https://www.keywordsai.co/blog/claude-sonnet-4-vs-claude-opus-4-a-comprehensive-comparison](https://www.keywordsai.co/blog/claude-sonnet-4-vs-claude-opus-4-a-comprehensive-comparison)
32. Understanding the Real Cost of AI Agents - AI Tools - God of Prompt, дата последнего обращения: июля 5, 2025, [https://www.godofprompt.ai/blog/understanding-the-real-cost-of-ai-agents](https://www.godofprompt.ai/blog/understanding-the-real-cost-of-ai-agents)
33. The AI Model Race: Claude 4 vs GPT-4.1 vs Gemini 2.5 Pro | by Divyansh Bhatia - Medium, дата последнего обращения: июля 5, 2025, [https://medium.com/@divyanshbhatiajm19/the-ai-model-race-claude-4-vs-gpt-4-1-vs-gemini-2-5-pro-dab5db064f3e](https://medium.com/@divyanshbhatiajm19/the-ai-model-race-claude-4-vs-gpt-4-1-vs-gemini-2-5-pro-dab5db064f3e)
34. Claude 4: A Comprehensive Analysis of Anthropic's Latest AI Breakthrough | by Ashish Chadha | May, 2025, дата последнего обращения: июля 5, 2025, [https://ashishchadha11944.medium.com/claude-4-anthropics-revolutionary-leap-in-ai-coding-and-reasoning-capabilities-fb9d539f500b](https://ashishchadha11944.medium.com/claude-4-anthropics-revolutionary-leap-in-ai-coding-and-reasoning-capabilities-fb9d539f500b)
35. Anthropic's Claude 4 (Opus & Sonnet): A Deep Dive into SOTA Coding, Reasoning & Autonomous AI - Appy Pie Ai, дата последнего обращения: июля 5, 2025, [https://www.appypievibe.ai/blog/claude-4-deep-dive](https://www.appypievibe.ai/blog/claude-4-deep-dive)
36. Claude 4 in 2025: Why You'd Use It, Where It Wins, and Where It Still Falls Short - Medium, дата последнего обращения: июля 5, 2025, [https://medium.com/@whatsupai/claude-4-in-2025-why-youd-use-it-where-it-wins-and-where-it-still-falls-short-947e268ec18c](https://medium.com/@whatsupai/claude-4-in-2025-why-youd-use-it-where-it-wins-and-where-it-still-falls-short-947e268ec18c)
37. How does Context Window Size Affect Prompt Performance of LLMs? [Tested], дата последнего обращения: июля 5, 2025, [https://www.allaboutai.com/geo/context-window-size/](https://www.allaboutai.com/geo/context-window-size/)
38. Leaderboard Comparing LLM Performance at Producing Hallucinations when Summarizing Short Documents - GitHub, дата последнего обращения: июля 5, 2025, [https://github.com/vectara/hallucination-leaderboard](https://github.com/vectara/hallucination-leaderboard)
39. Highlights from the Claude 4 system prompt - Simon Willison's Weblog, дата последнего обращения: июля 5, 2025, [https://simonwillison.net/2025/May/25/claude-4-system-prompt/](https://simonwillison.net/2025/May/25/claude-4-system-prompt/)
40. Anthropic's Claude 4 is OUT and Its Amazing! - Analytics Vidhya, дата последнего обращения: июля 5, 2025, [https://www.analyticsvidhya.com/blog/2025/05/anthropics-claude-4-is-out-and-its-amazing/](https://www.analyticsvidhya.com/blog/2025/05/anthropics-claude-4-is-out-and-its-amazing/)
41. Reduce hallucinations - Anthropic API, дата последнего обращения: июля 5, 2025, [https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-hallucinations](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-hallucinations)
42. Claude self-corrected mid sentence : r/ClaudeAI - Reddit, дата последнего обращения: июля 5, 2025, [https://www.reddit.com/r/ClaudeAI/comments/1gmr1m0/claude_selfcorrected_mid_sentence/](https://www.reddit.com/r/ClaudeAI/comments/1gmr1m0/claude_selfcorrected_mid_sentence/)
43. Claude keeps repeating the same mistake i told it to not do help : r/ClaudeAI - Reddit, дата последнего обращения: июля 5, 2025, [https://www.reddit.com/r/ClaudeAI/comments/1jihcdc/claude_keeps_repeating_the_same_mistake_i_told_it/](https://www.reddit.com/r/ClaudeAI/comments/1jihcdc/claude_keeps_repeating_the_same_mistake_i_told_it/)
44. Claude Sonnet 4 - Anthropic, дата последнего обращения: июля 5, 2025, [https://www.anthropic.com/claude/sonnet](https://www.anthropic.com/claude/sonnet)
45. Updating our Usage Policy - Anthropic, дата последнего обращения: июля 5, 2025, [https://www.anthropic.com/news/updating-our-usage-policy](https://www.anthropic.com/news/updating-our-usage-policy)
46. Acceptable Use Policy - Thomson Reuters, дата последнего обращения: июля 5, 2025, [https://www.thomsonreuters.com/content/dam/ewp-m/documents/thomsonreuters/en/pdf/third-party-restrictions/anthropic-aup.pdf](https://www.thomsonreuters.com/content/dam/ewp-m/documents/thomsonreuters/en/pdf/third-party-restrictions/anthropic-aup.pdf)
47. Court rules Anthropic's use of copyrighted books to train AI is 'fair use' – but it may not have much bearing on music rightsholders' case against platform's Claude - Music Business Worldwide, дата последнего обращения: июля 5, 2025, [https://www.musicbusinessworldwide.com/court-rules-anthropics-use-of-copyrighted-books-to-train-ai-is-fair-use-but-it-may-not-have-much-bearing-on-music-rightsholders-case-against-ai-giant/](https://www.musicbusinessworldwide.com/court-rules-anthropics-use-of-copyrighted-books-to-train-ai-is-fair-use-but-it-may-not-have-much-bearing-on-music-rightsholders-case-against-ai-giant/)
48. Very strange Claude "refusal" : r/ClaudeAI - Reddit, дата последнего обращения: июля 5, 2025, [https://www.reddit.com/r/ClaudeAI/comments/1bawiyl/very_strange_claude_refusal/](https://www.reddit.com/r/ClaudeAI/comments/1bawiyl/very_strange_claude_refusal/)
49. Claude 4 System Prompts : Operational Blueprint and Strategic Implications - Medium, дата последнего обращения: июля 5, 2025, [https://medium.com/@tuhinsharma121/decoding-claude-4-system-prompts-operational-blueprint-and-strategic-implications-727294cf79c3](https://medium.com/@tuhinsharma121/decoding-claude-4-system-prompts-operational-blueprint-and-strategic-implications-727294cf79c3)
50. Disappointed with Claude Opus | Can't make a summary : r/ClaudeAI - Reddit, дата последнего обращения: июля 5, 2025, [https://www.reddit.com/r/ClaudeAI/comments/1c69e2e/disappointed_with_claude_opus_cant_make_a_summary/](https://www.reddit.com/r/ClaudeAI/comments/1c69e2e/disappointed_with_claude_opus_cant_make_a_summary/)
51. System Card: Claude Opus 4 & Claude Sonnet 4 - Anthropic, дата последнего обращения: июля 5, 2025, [https://www-cdn.anthropic.com/4263b940cabb546aa0e3283f35b686f4f3b2ff47.pdf](https://www-cdn.anthropic.com/4263b940cabb546aa0e3283f35b686f4f3b2ff47.pdf)
52. Constitutional AI for dummies: 101 on what it is and why marketers should care, дата последнего обращения: июля 5, 2025, [https://www.marketing-interactive.com/constitutional-ai-dummies-101](https://www.marketing-interactive.com/constitutional-ai-dummies-101)
53. Claude's Constitution \ Anthropic, дата последнего обращения: июля 5, 2025, [https://www.anthropic.com/news/claudes-constitution](https://www.anthropic.com/news/claudes-constitution)
54. Constitutional AI: Harmlessness from AI Feedback - Anthropic, дата последнего обращения: июля 5, 2025, [https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf](https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf)
55. Anthropic's 'System Card' for Claude 4 (Opus and Sonnet) - Daring Fireball, дата последнего обращения: июля 5, 2025, [https://daringfireball.net/linked/2025/05/23/anthropic-claude-4-system-card](https://daringfireball.net/linked/2025/05/23/anthropic-claude-4-system-card)
56. Computer use tool - Anthropic API, дата последнего обращения: июля 5, 2025, [https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/computer-use-tool](https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/computer-use-tool)
57. Bridging Minds and Machines: Agents with Human-in-the-Loop – Frontier Research, Real-World Impact, and Tomorrow's Possibilities - Camel AI, дата последнего обращения: июля 5, 2025, [https://www.camel-ai.org/blogs/human-in-the-loop-ai-camel-integration](https://www.camel-ai.org/blogs/human-in-the-loop-ai-camel-integration)
58. 4. Add human-in-the-loop, дата последнего обращения: июля 5, 2025, [https://langchain-ai.github.io/langgraph/tutorials/get-started/4-human-in-the-loop/](https://langchain-ai.github.io/langgraph/tutorials/get-started/4-human-in-the-loop/)
59. Introducing Claude 4 in Amazon Bedrock, the most powerful models for coding from Anthropic | AWS News Blog, дата последнего обращения: июля 5, 2025, [https://aws.amazon.com/blogs/aws/claude-opus-4-anthropics-most-powerful-model-for-coding-is-now-in-amazon-bedrock/](https://aws.amazon.com/blogs/aws/claude-opus-4-anthropics-most-powerful-model-for-coding-is-now-in-amazon-bedrock/)
60. Intro to Claude - Anthropic API, дата последнего обращения: июля 5, 2025, [https://docs.anthropic.com/en/docs/intro-to-claude](https://docs.anthropic.com/en/docs/intro-to-claude)
61. Anthropic's Claude models | Generative AI on Vertex AI | Google Cloud, дата последнего обращения: июля 5, 2025, [https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude](https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude)